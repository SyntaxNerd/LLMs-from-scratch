{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXI8kw954x3aGL3p78ucVG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text data\n",
        "\n",
        "### 1. Tokenizing text\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cDbdOmsXqZHB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YPu-pKKphvd",
        "outputId": "276df275-ad21-480f-eb6a-98c36ff56fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
            "Total characters: 20479\n"
          ]
        }
      ],
      "source": [
        "# load the file --> the-verdict.txt\n",
        "with open('the-verdict.txt', 'r', encoding = 'utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(raw_text[:99])\n",
        "print('Total characters:', len(raw_text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re # regular expression module"
      ],
      "metadata": {
        "id": "48TLf2IitBWj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split on whitespaces\n",
        "text = 'Hello, world. This, is a test.'\n",
        "result = re.split(r'(\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rmxR1lIvFm5",
        "outputId": "0891c530-d267-4373-ce57-0fd6472e158b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split with punctuations and whitespaces\n",
        "result = re.split(r'([,.]|\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-sxAxg7vUEB",
        "outputId": "4f9b44c6-d4ec-4bcd-b638-02485020dc19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split without whitespace --> better for LLMs\n",
        "result = re.split(r'([,.]|\\s)', text)\n",
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h7Ao9rqyFSF",
        "outputId": "f4bf95b7-9b32-4d0e-bb54-c479b4d0e739"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# complex split\n",
        "text = 'Hello, world. Is this-- a test?'\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpPRW4WZynoa",
        "outputId": "0b3a8891-69e7-4eef-dd36-25b5ac7f173f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the entire story\n",
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LET5wB_nzniI",
        "outputId": "86ebf46d-f41f-4d72-ca40-ef56d17c2c87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--', 'deploring', 'his', 'unaccountable', 'abdication', '.', '\"', 'Of', 'course', 'it', \"'\", 's', 'going', 'to', 'send', 'the', 'value', 'of', 'my', 'picture', \"'\", 'way', 'up', ';', 'but', 'I', 'don', \"'\", 't', 'think', 'of', 'that', ',', 'Mr', '.', 'Rickham', '--', 'the', 'loss', 'to', 'Arrt', 'is', 'all', 'I', 'think', 'of', '.', '\"', 'The', 'word', ',', 'on', 'Mrs', '.', 'Thwing', \"'\", 's', 'lips', ',', 'multiplied', 'its', '_', 'rs', '_', 'as', 'though', 'they', 'were', 'reflected', 'in', 'an', 'endless', 'vista', 'of', 'mirrors', '.', 'And', 'it', 'was', 'not', 'only', 'the', 'Mrs', '.', 'Thwings', 'who', 'mourned', '.', 'Had', 'not', 'the', 'exquisite', 'Hermia', 'Croft', ',', 'at', 'the', 'last', 'Grafton', 'Gallery', 'show', ',', 'stopped', 'me', 'before', 'Gisburn', \"'\", 's', '\"', 'Moon-dancers', '\"', 'to', 'say', ',', 'with', 'tears', 'in', 'her', 'eyes', ':', '\"', 'We', 'shall', 'not', 'look', 'upon', 'its', 'like', 'again', '\"', '?', 'Well', '!', '--', 'even', 'through', 'the', 'prism', 'of', 'Hermia', \"'\", 's', 'tears', 'I', 'felt', 'able', 'to', 'face', 'the', 'fact', 'with', 'equanimity', '.', 'Poor', 'Jack', 'Gisburn', '!', 'The', 'women', 'had', 'made', 'him', '--', 'it', 'was', 'fitting', 'that', 'they', 'should', 'mourn', 'him', '.', 'Among', 'his', 'own', 'sex', 'fewer', 'regrets', 'were', 'heard', ',', 'and', 'in', 'his', 'own', 'trade', 'hardly', 'a', 'murmur', '.', 'Professional', 'jealousy', '?', 'Perhaps', '.', 'If', 'it', 'were', ',', 'the', 'honour', 'of', 'the', 'craft', 'was', 'vindicated', 'by', 'little', 'Claude', 'Nutley', ',', 'who', ',', 'in', 'all', 'good', 'faith', ',', 'brought', 'out', 'in', 'the', 'Burlington', 'a', 'very', 'handsome', '\"', 'obituary', '\"', 'on', 'Jack', '--', 'one', 'of', 'those', 'showy', 'articles', 'stocked', 'with', 'random', 'technicalities', 'that', 'I', 'have', 'heard', '(', 'I', 'won', \"'\", 't', 'say', 'by', 'whom', ')', 'compared', 'to', 'Gisburn', \"'\", 's', 'painting', '.', 'And', 'so', '--', 'his', 'resolve', 'being', 'apparently', 'irrevocable', '--', 'the', 'discussion', 'gradually', 'died', 'out', ',', 'and', ',', 'as', 'Mrs', '.', 'Thwing', 'had', 'predicted', ',', 'the', 'price', 'of', '\"', 'Gisburns', '\"', 'went', 'up', '.', 'It', 'was', 'not', 'till', 'three', 'years', 'later', 'that', ',', 'in', 'the', 'course', 'of', 'a', 'few', 'weeks', \"'\", 'idling', 'on', 'the', 'Riviera', ',', 'it', 'suddenly', 'occurred', 'to', 'me', 'to', 'wonder', 'why', 'Gisburn', 'had', 'given', 'up', 'his', 'painting', '.', 'On', 'reflection', ',', 'it', 'really', 'was', 'a', 'tempting', 'problem', '.', 'To', 'accuse', 'his', 'wife', 'would', 'have', 'been', 'too', 'easy', '--', 'his', 'fair', 'sitters', 'had', 'been', 'denied', 'the', 'solace', 'of', 'saying', 'that', 'Mrs', '.', 'Gisburn', 'had', '\"', 'dragged', 'him', 'down', '.', '\"', 'For', 'Mrs', '.', 'Gisburn', '--', 'as', 'such', '--', 'had', 'not', 'existed', 'till', 'nearly', 'a', 'year', 'after', 'Jack', \"'\", 's', 'resolve', 'had', 'been', 'taken', '.', 'It', 'might', 'be', 'that', 'he', 'had', 'married', 'her', '--', 'since', 'he', 'liked', 'his', 'ease', '--', 'because', 'he', 'didn', \"'\", 't', 'want', 'to', 'go', 'on', 'painting', ';', 'but', 'it', 'would', 'have', 'been', 'hard', 'to', 'prove', 'that', 'he', 'had', 'given', 'up', 'his', 'painting', 'because', 'he', 'had', 'married', 'her', '.', 'Of', 'course', ',', 'if', 'she', 'had', 'not', 'dragged', 'him', 'down', ',', 'she', 'had', 'equally', ',', 'as', 'Miss', 'Croft', 'contended', ',', 'failed', 'to', '\"', 'lift', 'him', 'up', '\"', '--', 'she', 'had', 'not', 'led', 'him', 'back', 'to', 'the', 'easel', '.', 'To', 'put', 'the', 'brush', 'into', 'his', 'hand', 'again', '--', 'what', 'a', 'vocation', 'for', 'a', 'wife', '!', 'But', 'Mrs', '.', 'Gisburn', 'appeared', 'to', 'have', 'disdained', 'it', '--', 'and', 'I', 'felt', 'it', 'might', 'be', 'interesting', 'to', 'find', 'out', 'why', '.', 'The', 'desultory', 'life', 'of', 'the', 'Riviera', 'lends', 'itself', 'to', 'such', 'purely', 'academic', 'speculations', ';', 'and', 'having', ',', 'on', 'my', 'way', 'to', 'Monte', 'Carlo', ',', 'caught', 'a', 'glimpse', 'of', 'Jack', \"'\", 's', 'balustraded', 'terraces', 'between', 'the', 'pines', ',', 'I', 'had', 'myself', 'borne', 'thither', 'the', 'next', 'day', '.', 'I', 'found', 'the', 'couple', 'at', 'tea', 'beneath', 'their', 'palm-trees', ';', 'and', 'Mrs', '.', 'Gisburn', \"'\", 's', 'welcome', 'was', 'so', 'genial', 'that', ',', 'in', 'the', 'ensuing', 'weeks', ',', 'I', 'claimed', 'it', 'frequently', '.', 'It', 'was', 'not', 'that', 'my', 'hostess', 'was', '\"', 'interesting', '\"', ':', 'on', 'that', 'point', 'I', 'could', 'have', 'given', 'Miss', 'Croft', 'the', 'fullest', 'reassurance', '.', 'It', 'was', 'just', 'because', 'she', 'was', '_', 'not', '_', 'interesting', '--', 'if', 'I', 'may', 'be', 'pardoned', 'the', 'bull', '--', 'that', 'I', 'found', 'her', 'so', '.', 'For', 'Jack', ',', 'all', 'his', 'life', ',', 'had', 'been', 'surrounded', 'by', 'interesting', 'women', ':', 'they', 'had', 'fostered', 'his', 'art', ',', 'it', 'had', 'been', 'reared', 'in', 'the', 'hot-house', 'of', 'their', 'adulation', '.', 'And', 'it', 'was', 'therefore', 'instructive', 'to', 'note', 'what', 'effect', 'the', '\"', 'deadening', 'atmosphere', 'of', 'mediocrity', '\"', '(', 'I', 'quote', 'Miss', 'Croft', ')', 'was', 'having', 'on', 'him', '.', 'I', 'have', 'mentioned', 'that', 'Mrs', '.', 'Gisburn', 'was', 'rich', ';', 'and', 'it', 'was', 'immediately', 'perceptible', 'that', 'her', 'husband', 'was', 'extracting', 'from', 'this', 'circumstance', 'a', 'delicate', 'but', 'substantial', 'satisfaction', '.', 'It', 'is', ',', 'as', 'a', 'rule', ',', 'the', 'people', 'who', 'scorn', 'money', 'who', 'get', 'most', 'out', 'of', 'it', ';', 'and', 'Jack', \"'\", 's', 'elegant', 'disdain', 'of', 'his', 'wife', \"'\", 's', 'big', 'balance', 'enabled', 'him', ',', 'with', 'an', 'appearance', 'of', 'perfect', 'good-breeding', ',', 'to', 'transmute', 'it', 'into', 'objects', 'of', 'art', 'and', 'luxury', '.', 'To', 'the', 'latter', ',', 'I', 'must', 'add', ',', 'he', 'remained', 'relatively', 'indifferent', ';', 'but', 'he', 'was', 'buying', 'Renaissance', 'bronzes', 'and', 'eighteenth-century', 'pictures', 'with', 'a', 'discrimination', 'that', 'bespoke', 'the', 'amplest', 'resources', '.', '\"', 'Money', \"'\", 's', 'only', 'excuse', 'is', 'to', 'put', 'beauty', 'into', 'circulation', ',', '\"', 'was', 'one', 'of', 'the', 'axioms', 'he', 'laid', 'down', 'across', 'the', 'Sevres', 'and', 'silver', 'of', 'an', 'exquisitely', 'appointed', 'luncheon-table', ',', 'when', ',', 'on', 'a', 'later', 'day', ',', 'I', 'had', 'again', 'run', 'over', 'from', 'Monte', 'Carlo', ';', 'and', 'Mrs', '.', 'Gisburn', ',', 'beaming', 'on', 'him', ',', 'added', 'for', 'my', 'enlightenment', ':', '\"', 'Jack', 'is', 'so', 'morbidly', 'sensitive', 'to', 'every', 'form', 'of', 'beauty', '.', '\"', 'Poor', 'Jack', '!', 'It', 'had', 'always', 'been', 'his', 'fate', 'to', 'have', 'women', 'say', 'such', 'things', 'of', 'him', ':', 'the', 'fact', 'should', 'be', 'set', 'down', 'in', 'extenuation', '.', 'What', 'struck', 'me', 'now', 'was', 'that', ',', 'for', 'the', 'first', 'time', ',', 'he', 'resented', 'the', 'tone', '.', 'I', 'had', 'seen', 'him', ',', 'so', 'often', ',', 'basking', 'under', 'similar', 'tributes', '--', 'was', 'it', 'the', 'conjugal', 'note', 'that', 'robbed', 'them', 'of', 'their', 'savour', '?', 'No', '--', 'for', ',', 'oddly', 'enough', ',', 'it', 'became', 'apparent', 'that', 'he', 'was', 'fond', 'of', 'Mrs', '.', 'Gisburn', '--', 'fond', 'enough', 'not', 'to', 'see', 'her', 'absurdity', '.', 'It', 'was', 'his', 'own', 'absurdity', 'he', 'seemed', 'to', 'be', 'wincing', 'under', '--', 'his', 'own', 'attitude', 'as', 'an', 'object', 'for', 'garlands', 'and', 'incense', '.', '\"', 'My', 'dear', ',', 'since', 'I', \"'\", 've', 'chucked', 'painting', 'people', 'don', \"'\", 't', 'say', 'that', 'stuff', 'about', 'me', '--', 'they', 'say', 'it', 'about', 'Victor', 'Grindle', ',', '\"', 'was', 'his', 'only', 'protest', ',', 'as', 'he', 'rose', 'from', 'the', 'table', 'and', 'strolled', 'out', 'onto', 'the', 'sunlit', 'terrace', '.', 'I', 'glanced', 'after', 'him', ',', 'struck', 'by', 'his', 'last', 'word', '.', 'Victor', 'Grindle', 'was', ',', 'in', 'fact', ',', 'becoming', 'the', 'man', 'of', 'the', 'moment', '--', 'as', 'Jack', 'himself', ',', 'one', 'might', 'put', 'it', ',', 'had', 'been', 'the', 'man', 'of', 'the', 'hour', '.', 'The', 'younger', 'artist', 'was', 'said', 'to', 'have', 'formed', 'himself', 'at', 'my', 'friend', \"'\", 's', 'feet', ',', 'and', 'I', 'wondered', 'if', 'a', 'tinge', 'of', 'jealousy', 'underlay', 'the', 'latter', \"'\", 's', 'mysterious', 'abdication', '.', 'But', 'no', '--', 'for', 'it', 'was', 'not', 'till', 'after', 'that', 'event', 'that', 'the', '_', 'rose', 'Dubarry', '_', 'drawing-rooms', 'had', 'begun', 'to', 'display', 'their', '\"', 'Grindles', '.', '\"', 'I', 'turned', 'to', 'Mrs', '.', 'Gisburn', ',', 'who', 'had', 'lingered', 'to', 'give', 'a', 'lump', 'of', 'sugar', 'to', 'her', 'spaniel', 'in', 'the', 'dining-room', '.', '\"', 'Why', '_', 'has', '_', 'he', 'chucked', 'painting', '?', '\"', 'I', 'asked', 'abruptly', '.', 'She', 'raised', 'her', 'eyebrows', 'with', 'a', 'hint', 'of', 'good-humoured', 'surprise', '.', '\"', 'Oh', ',', 'he', 'doesn', \"'\", 't', '_', 'have', '_', 'to', 'now', ',', 'you', 'know', ';', 'and', 'I', 'want', 'him', 'to', 'enjoy', 'himself', ',', '\"', 'she', 'said', 'quite', 'simply', '.', 'I', 'looked', 'about', 'the', 'spacious', 'white-panelled', 'room', ',', 'with', 'its', '_', 'famille-verte', '_', 'vases', 'repeating', 'the', 'tones', 'of', 'the', 'pale', 'damask', 'curtains', ',', 'and', 'its', 'eighteenth-century', 'pastels', 'in', 'delicate', 'faded', 'frames', '.', '\"', 'Has', 'he', 'chucked', 'his', 'pictures', 'too', '?', 'I', 'haven', \"'\", 't', 'seen', 'a', 'single', 'one', 'in', 'the', 'house', '.', '\"', 'A', 'slight', 'shade', 'of', 'constraint', 'crossed', 'Mrs', '.', 'Gisburn', \"'\", 's', 'open', 'countenance', '.', '\"', 'It', \"'\", 's', 'his', 'ridiculous', 'modesty', ',', 'you', 'know', '.', 'He', 'says', 'they', \"'\", 're', 'not', 'fit', 'to', 'have', 'about', ';', 'he', \"'\", 's', 'sent', 'them', 'all', 'away', 'except', 'one', '--', 'my', 'portrait', '--', 'and', 'that', 'I', 'have', 'to', 'keep', 'upstairs', '.', '\"', 'His', 'ridiculous', 'modesty', '--', 'Jack', \"'\", 's', 'modesty', 'about', 'his', 'pictures', '?', 'My', 'curiosity', 'was', 'growing', 'like', 'the', 'bean-stalk', '.', 'I', 'said', 'persuasively', 'to', 'my', 'hostess', ':', '\"', 'I', 'must', 'really', 'see', 'your', 'portrait', ',', 'you', 'know', '.', '\"', 'She', 'glanced', 'out', 'almost', 'timorously', 'at', 'the', 'terrace', 'where', 'her', 'husband', ',', 'lounging', 'in', 'a', 'hooded', 'chair', ',', 'had', 'lit', 'a', 'cigar', 'and', 'drawn', 'the', 'Russian', 'deerhound', \"'\", 's', 'head', 'between', 'his', 'knees', '.', '\"', 'Well', ',', 'come', 'while', 'he', \"'\", 's', 'not', 'looking', ',', '\"', 'she', 'said', ',', 'with', 'a', 'laugh', 'that', 'tried', 'to', 'hide', 'her', 'nervousness', ';', 'and', 'I', 'followed', 'her', 'between', 'the', 'marble', 'Emperors', 'of', 'the', 'hall', ',', 'and', 'up', 'the', 'wide', 'stairs', 'with', 'terra-cotta', 'nymphs', 'poised', 'among', 'flowers', 'at', 'each', 'landing', '.', 'In', 'the', 'dimmest', 'corner', 'of', 'her', 'boudoir', ',', 'amid', 'a', 'profusion', 'of', 'delicate', 'and', 'distinguished', 'objects', ',', 'hung', 'one', 'of', 'the', 'familiar', 'oval', 'canvases', ',', 'in', 'the', 'inevitable', 'garlanded', 'frame', '.', 'The', 'mere', 'outline', 'of', 'the', 'frame', 'called', 'up', 'all', 'Gisburn', \"'\", 's', 'past', '!', 'Mrs', '.', 'Gisburn', 'drew', 'back', 'the', 'window-curtains', ',', 'moved', 'aside', 'a', '_', 'jardiniere', '_', 'full', 'of', 'pink', 'azaleas', ',', 'pushed', 'an', 'arm-chair', 'away', ',', 'and', 'said', ':', '\"', 'If', 'you', 'stand', 'here', 'you', 'can', 'just', 'manage', 'to', 'see', 'it', '.', 'I', 'had', 'it', 'over', 'the', 'mantel-piece', ',', 'but', 'he', 'wouldn', \"'\", 't', 'let', 'it', 'stay', '.', '\"', 'Yes', '--', 'I', 'could', 'just', 'manage', 'to', 'see', 'it', '--', 'the', 'first', 'portrait', 'of', 'Jack', \"'\", 's', 'I', 'had', 'ever', 'had', 'to', 'strain', 'my', 'eyes', 'over', '!', 'Usually', 'they', 'had', 'the', 'place', 'of', 'honour', '--', 'say', 'the', 'central', 'panel', 'in', 'a', 'pale', 'yellow', 'or', '_', 'rose', 'Dubarry', '_', 'drawing-room', ',', 'or', 'a', 'monumental', 'easel', 'placed', 'so', 'that', 'it', 'took', 'the', 'light', 'through', 'curtains', 'of', 'old', 'Venetian', 'point', '.', 'The', 'more', 'modest', 'place', 'became', 'the', 'picture', 'better', ';', 'yet', ',', 'as', 'my', 'eyes', 'grew', 'accustomed', 'to', 'the', 'half-light', ',', 'all', 'the', 'characteristic', 'qualities', 'came', 'out', '--', 'all', 'the', 'hesitations', 'disguised', 'as', 'audacities', ',', 'the', 'tricks', 'of', 'prestidigitation', 'by', 'which', ',', 'with', 'such', 'consummate', 'skill', ',', 'he', 'managed', 'to', 'divert', 'attention', 'from', 'the', 'real', 'business', 'of', 'the', 'picture', 'to', 'some', 'pretty', 'irrelevance', 'of', 'detail', '.', 'Mrs', '.', 'Gisburn', ',', 'presenting', 'a', 'neutral', 'surface', 'to', 'work', 'on', '--', 'forming', ',', 'as', 'it', 'were', ',', 'so', 'inevitably', 'the', 'background', 'of', 'her', 'own', 'picture', '--', 'had', 'lent', 'herself', 'in', 'an', 'unusual', 'degree', 'to', 'the', 'display', 'of', 'this', 'false', 'virtuosity', '.', 'The', 'picture', 'was', 'one', 'of', 'Jack', \"'\", 's', '\"', 'strongest', ',', '\"', 'as', 'his', 'admirers', 'would', 'have', 'put', 'it', '--', 'it', 'represented', ',', 'on', 'his', 'part', ',', 'a', 'swelling', 'of', 'muscles', ',', 'a', 'congesting', 'of', 'veins', ',', 'a', 'balancing', ',', 'straddling', 'and', 'straining', ',', 'that', 'reminded', 'one', 'of', 'the', 'circus-clown', \"'\", 's', 'ironic', 'efforts', 'to', 'lift', 'a', 'feather', '.', 'It', 'met', ',', 'in', 'short', ',', 'at', 'every', 'point', 'the', 'demand', 'of', 'lovely', 'woman', 'to', 'be', 'painted', '\"', 'strongly', '\"', 'because', 'she', 'was', 'tired', 'of', 'being', 'painted', '\"', 'sweetly', '\"', '--', 'and', 'yet', 'not', 'to', 'lose', 'an', 'atom', 'of', 'the', 'sweetness', '.', '\"', 'It', \"'\", 's', 'the', 'last', 'he', 'painted', ',', 'you', 'know', ',', '\"', 'Mrs', '.', 'Gisburn', 'said', 'with', 'pardonable', 'pride', '.', '\"', 'The', 'last', 'but', 'one', ',', '\"', 'she', 'corrected', 'herself', '--', '\"', 'but', 'the', 'other', 'doesn', \"'\", 't', 'count', ',', 'because', 'he', 'destroyed', 'it', '.', '\"', '\"', 'Destroyed', 'it', '?', '\"', 'I', 'was', 'about', 'to', 'follow', 'up', 'this', 'clue', 'when', 'I', 'heard', 'a', 'footstep', 'and', 'saw', 'Jack', 'himself', 'on', 'the', 'threshold', '.', 'As', 'he', 'stood', 'there', ',', 'his', 'hands', 'in', 'the', 'pockets', 'of', 'his', 'velveteen', 'coat', ',', 'the', 'thin', 'brown', 'waves', 'of', 'hair', 'pushed', 'back', 'from', 'his', 'white', 'forehead', ',', 'his', 'lean', 'sunburnt', 'cheeks', 'furrowed', 'by', 'a', 'smile', 'that', 'lifted', 'the', 'tips', 'of', 'a', 'self-confident', 'moustache', ',', 'I', 'felt', 'to', 'what', 'a', 'degree', 'he', 'had', 'the', 'same', 'quality', 'as', 'his', 'pictures', '--', 'the', 'quality', 'of', 'looking', 'cleverer', 'than', 'he', 'was', '.', 'His', 'wife', 'glanced', 'at', 'him', 'deprecatingly', ',', 'but', 'his', 'eyes', 'travelled', 'past', 'her', 'to', 'the', 'portrait', '.', '\"', 'Mr', '.', 'Rickham', 'wanted', 'to', 'see', 'it', ',', '\"', 'she', 'began', ',', 'as', 'if', 'excusing', 'herself', '.', 'He', 'shrugged', 'his', 'shoulders', ',', 'still', 'smiling', '.', '\"', 'Oh', ',', 'Rickham', 'found', 'me', 'out', 'long', 'ago', ',', '\"', 'he', 'said', 'lightly', ';', 'then', ',', 'passing', 'his', 'arm', 'through', 'mine', ':', '\"', 'Come', 'and', 'see', 'the', 'rest', 'of', 'the', 'house', '.', '\"', 'He', 'showed', 'it', 'to', 'me', 'with', 'a', 'kind', 'of', 'naive', 'suburban', 'pride', ':', 'the', 'bath-rooms', ',', 'the', 'speaking-tubes', ',', 'the', 'dress-closets', ',', 'the', 'trouser-presses', '--', 'all', 'the', 'complex', 'simplifications', 'of', 'the', 'millionaire', \"'\", 's', 'domestic', 'economy', '.', 'And', 'whenever', 'my', 'wonder', 'paid', 'the', 'expected', 'tribute', 'he', 'said', ',', 'throwing', 'out', 'his', 'chest', 'a', 'little', ':', '\"', 'Yes', ',', 'I', 'really', 'don', \"'\", 't', 'see', 'how', 'people', 'manage', 'to', 'live', 'without', 'that', '.', '\"', 'Well', '--', 'it', 'was', 'just', 'the', 'end', 'one', 'might', 'have', 'foreseen', 'for', 'him', '.', 'Only', 'he', 'was', ',', 'through', 'it', 'all', 'and', 'in', 'spite', 'of', 'it', 'all', '--', 'as', 'he', 'had', 'been', 'through', ',', 'and', 'in', 'spite', 'of', ',', 'his', 'pictures', '--', 'so', 'handsome', ',', 'so', 'charming', ',', 'so', 'disarming', ',', 'that', 'one', 'longed', 'to', 'cry', 'out', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'leisure', '!', '\"', 'as', 'once', 'one', 'had', 'longed', 'to', 'say', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'work', '!', '\"', 'But', ',', 'with', 'the', 'cry', 'on', 'my', 'lips', ',', 'my', 'diagnosis', 'suffered', 'an', 'unexpected', 'check', '.', '\"', 'This', 'is', 'my', 'own', 'lair', ',', '\"', 'he', 'said', ',', 'leading', 'me', 'into', 'a', 'dark', 'plain', 'room', 'at', 'the', 'end', 'of', 'the', 'florid', 'vista', '.', 'It', 'was', 'square', 'and', 'brown', 'and', 'leathery', ':', 'no', '\"', 'effects', '\"', ';', 'no', 'bric-a-brac', ',', 'none', 'of', 'the', 'air', 'of', 'posing', 'for', 'reproduction', 'in', 'a', 'picture', 'weekly', '--', 'above', 'all', ',', 'no', 'least', 'sign', 'of', 'ever', 'having', 'been', 'used', 'as', 'a', 'studio', '.', 'The', 'fact', 'brought', 'home', 'to', 'me', 'the', 'absolute', 'finality', 'of', 'Jack', \"'\", 's', 'break', 'with', 'his', 'old', 'life', '.', '\"', 'Don', \"'\", 't', 'you', 'ever', 'dabble', 'with', 'paint', 'any', 'more', '?', '\"', 'I', 'asked', ',', 'still', 'looking', 'about', 'for', 'a', 'trace', 'of', 'such', 'activity', '.', '\"', 'Never', ',', '\"', 'he', 'said', 'briefly', '.', '\"', 'Or', 'water-colour', '--', 'or', 'etching', '?', '\"', 'His', 'confident', 'eyes', 'grew', 'dim', ',', 'and', 'his', 'cheeks', 'paled', 'a', 'little', 'under', 'their', 'handsome', 'sunburn', '.', '\"', 'Never', 'think', 'of', 'it', ',', 'my', 'dear', 'fellow', '--', 'any', 'more', 'than', 'if', 'I', \"'\", 'd', 'never', 'touched', 'a', 'brush', '.', '\"', 'And', 'his', 'tone', 'told', 'me', 'in', 'a', 'flash', 'that', 'he', 'never', 'thought', 'of', 'anything', 'else', '.', 'I', 'moved', 'away', ',', 'instinctively', 'embarrassed', 'by', 'my', 'unexpected', 'discovery', ';', 'and', 'as', 'I', 'turned', ',', 'my', 'eye', 'fell', 'on', 'a', 'small', 'picture', 'above', 'the', 'mantel-piece', '--', 'the', 'only', 'object', 'breaking', 'the', 'plain', 'oak', 'panelling', 'of', 'the', 'room', '.', '\"', 'Oh', ',', 'by', 'Jove', '!', '\"', 'I', 'said', '.', 'It', 'was', 'a', 'sketch', 'of', 'a', 'donkey', '--', 'an', 'old', 'tired', 'donkey', ',', 'standing', 'in', 'the', 'rain', 'under', 'a', 'wall', '.', '\"', 'By', 'Jove', '--', 'a', 'Stroud', '!', '\"', 'I', 'cried', '.', 'He', 'was', 'silent', ';', 'but', 'I', 'felt', 'him', 'close', 'behind', 'me', ',', 'breathing', 'a', 'little', 'quickly', '.', '\"', 'What', 'a', 'wonder', '!', 'Made', 'with', 'a', 'dozen', 'lines', '--', 'but', 'on', 'everlasting', 'foundations', '.', 'You', 'lucky', 'chap', ',', 'where', 'did', 'you', 'get', 'it', '?', '\"', 'He', 'answered', 'slowly', ':', '\"', 'Mrs', '.', 'Stroud', 'gave', 'it', 'to', 'me', '.', '\"', '\"', 'Ah', '--', 'I', 'didn', \"'\", 't', 'know', 'you', 'even', 'knew', 'the', 'Strouds', '.', 'He', 'was', 'such', 'an', 'inflexible', 'hermit', '.', '\"', '\"', 'I', 'didn', \"'\", 't', '--', 'till', 'after', '.', '.', '.', '.', 'She', 'sent', 'for', 'me', 'to', 'paint', 'him', 'when', 'he', 'was', 'dead', '.', '\"', '\"', 'When', 'he', 'was', 'dead', '?', 'You', '?', '\"', 'I', 'must', 'have', 'let', 'a', 'little', 'too', 'much', 'amazement', 'escape', 'through', 'my', 'surprise', ',', 'for', 'he', 'answered', 'with', 'a', 'deprecating', 'laugh', ':', '\"', 'Yes', '--', 'she', \"'\", 's', 'an', 'awful', 'simpleton', ',', 'you', 'know', ',', 'Mrs', '.', 'Stroud', '.', 'Her', 'only', 'idea', 'was', 'to', 'have', 'him', 'done', 'by', 'a', 'fashionable', 'painter', '--', 'ah', ',', 'poor', 'Stroud', '!', 'She', 'thought', 'it', 'the', 'surest', 'way', 'of', 'proclaiming', 'his', 'greatness', '--', 'of', 'forcing', 'it', 'on', 'a', 'purblind', 'public', '.', 'And', 'at', 'the', 'moment', 'I', 'was', '_', 'the', '_', 'fashionable', 'painter', '.', '\"', '\"', 'Ah', ',', 'poor', 'Stroud', '--', 'as', 'you', 'say', '.', 'Was', '_', 'that', '_', 'his', 'history', '?', '\"', '\"', 'That', 'was', 'his', 'history', '.', 'She', 'believed', 'in', 'him', ',', 'gloried', 'in', 'him', '--', 'or', 'thought', 'she', 'did', '.', 'But', 'she', 'couldn', \"'\", 't', 'bear', 'not', 'to', 'have', 'all', 'the', 'drawing-rooms', 'with', 'her', '.', 'She', 'couldn', \"'\", 't', 'bear', 'the', 'fact', 'that', ',', 'on', 'varnishing', 'days', ',', 'one', 'could', 'always', 'get', 'near', 'enough', 'to', 'see', 'his', 'pictures', '.', 'Poor', 'woman', '!', 'She', \"'\", 's', 'just', 'a', 'fragment', 'groping', 'for', 'other', 'fragments', '.', 'Stroud', 'is', 'the', 'only', 'whole', 'I', 'ever', 'knew', '.', '\"', '\"', 'You', 'ever', 'knew', '?', 'But', 'you', 'just', 'said', '--', '\"', 'Gisburn', 'had', 'a', 'curious', 'smile', 'in', 'his', 'eyes', '.', '\"', 'Oh', ',', 'I', 'knew', 'him', ',', 'and', 'he', 'knew', 'me', '--', 'only', 'it', 'happened', 'after', 'he', 'was', 'dead', '.', '\"', 'I', 'dropped', 'my', 'voice', 'instinctively', '.', '\"', 'When', 'she', 'sent', 'for', 'you', '?', '\"', '\"', 'Yes', '--', 'quite', 'insensible', 'to', 'the', 'irony', '.', 'She', 'wanted', 'him', 'vindicated', '--', 'and', 'by', 'me', '!', '\"', 'He', 'laughed', 'again', ',', 'and', 'threw', 'back', 'his', 'head', 'to', 'look', 'up', 'at', 'the', 'sketch', 'of', 'the', 'donkey', '.', '\"', 'There', 'were', 'days', 'when', 'I', 'couldn', \"'\", 't', 'look', 'at', 'that', 'thing', '--', 'couldn', \"'\", 't', 'face', 'it', '.', 'But', 'I', 'forced', 'myself', 'to', 'put', 'it', 'here', ';', 'and', 'now', 'it', \"'\", 's', 'cured', 'me', '--', 'cured', 'me', '.', 'That', \"'\", 's', 'the', 'reason', 'why', 'I', 'don', \"'\", 't', 'dabble', 'any', 'more', ',', 'my', 'dear', 'Rickham', ';', 'or', 'rather', 'Stroud', 'himself', 'is', 'the', 'reason', '.', '\"', 'For', 'the', 'first', 'time', 'my', 'idle', 'curiosity', 'about', 'my', 'companion', 'turned', 'into', 'a', 'serious', 'desire', 'to', 'understand', 'him', 'better', '.', '\"', 'I', 'wish', 'you', \"'\", 'd', 'tell', 'me', 'how', 'it', 'happened', ',', '\"', 'I', 'said', '.', 'He', 'stood', 'looking', 'up', 'at', 'the', 'sketch', ',', 'and', 'twirling', 'between', 'his', 'fingers', 'a', 'cigarette', 'he', 'had', 'forgotten', 'to', 'light', '.', 'Suddenly', 'he', 'turned', 'toward', 'me', '.', '\"', 'I', \"'\", 'd', 'rather', 'like', 'to', 'tell', 'you', '--', 'because', 'I', \"'\", 've', 'always', 'suspected', 'you', 'of', 'loathing', 'my', 'work', '.', '\"', 'I', 'made', 'a', 'deprecating', 'gesture', ',', 'which', 'he', 'negatived', 'with', 'a', 'good-humoured', 'shrug', '.', '\"', 'Oh', ',', 'I', 'didn', \"'\", 't', 'care', 'a', 'straw', 'when', 'I', 'believed', 'in', 'myself', '--', 'and', 'now', 'it', \"'\", 's', 'an', 'added', 'tie', 'between', 'us', '!', '\"', 'He', 'laughed', 'slightly', ',', 'without', 'bitterness', ',', 'and', 'pushed', 'one', 'of', 'the', 'deep', 'arm-chairs', 'forward', '.', '\"', 'There', ':', 'make', 'yourself', 'comfortable', '--', 'and', 'here', 'are', 'the', 'cigars', 'you', 'like', '.', '\"', 'He', 'placed', 'them', 'at', 'my', 'elbow', 'and', 'continued', 'to', 'wander', 'up', 'and', 'down', 'the', 'room', ',', 'stopping', 'now', 'and', 'then', 'beneath', 'the', 'picture', '.', '\"', 'How', 'it', 'happened', '?', 'I', 'can', 'tell', 'you', 'in', 'five', 'minutes', '--', 'and', 'it', 'didn', \"'\", 't', 'take', 'much', 'longer', 'to', 'happen', '.', '.', '.', '.', 'I', 'can', 'remember', 'now', 'how', 'surprised', 'and', 'pleased', 'I', 'was', 'when', 'I', 'got', 'Mrs', '.', 'Stroud', \"'\", 's', 'note', '.', 'Of', 'course', ',', 'deep', 'down', ',', 'I', 'had', 'always', '_', 'felt', '_', 'there', 'was', 'no', 'one', 'like', 'him', '--', 'only', 'I', 'had', 'gone', 'with', 'the', 'stream', ',', 'echoed', 'the', 'usual', 'platitudes', 'about', 'him', ',', 'till', 'I', 'half', 'got', 'to', 'think', 'he', 'was', 'a', 'failure', ',', 'one', 'of', 'the', 'kind', 'that', 'are', 'left', 'behind', '.', 'By', 'Jove', ',', 'and', 'he', '_', 'was', '_', 'left', 'behind', '--', 'because', 'he', 'had', 'come', 'to', 'stay', '!', 'The', 'rest', 'of', 'us', 'had', 'to', 'let', 'ourselves', 'be', 'swept', 'along', 'or', 'go', 'under', ',', 'but', 'he', 'was', 'high', 'above', 'the', 'current', '--', 'on', 'everlasting', 'foundations', ',', 'as', 'you', 'say', '.', '\"', 'Well', ',', 'I', 'went', 'off', 'to', 'the', 'house', 'in', 'my', 'most', 'egregious', 'mood', '--', 'rather', 'moved', ',', 'Lord', 'forgive', 'me', ',', 'at', 'the', 'pathos', 'of', 'poor', 'Stroud', \"'\", 's', 'career', 'of', 'failure', 'being', 'crowned', 'by', 'the', 'glory', 'of', 'my', 'painting', 'him', '!', 'Of', 'course', 'I', 'meant', 'to', 'do', 'the', 'picture', 'for', 'nothing', '--', 'I', 'told', 'Mrs', '.', 'Stroud', 'so', 'when', 'she', 'began', 'to', 'stammer', 'something', 'about', 'her', 'poverty', '.', 'I', 'remember', 'getting', 'off', 'a', 'prodigious', 'phrase', 'about', 'the', 'honour', 'being', '_', 'mine', '_', '--', 'oh', ',', 'I', 'was', 'princely', ',', 'my', 'dear', 'Rickham', '!', 'I', 'was', 'posing', 'to', 'myself', 'like', 'one', 'of', 'my', 'own', 'sitters', '.', '\"', 'Then', 'I', 'was', 'taken', 'up', 'and', 'left', 'alone', 'with', 'him', '.', 'I', 'had', 'sent', 'all', 'my', 'traps', 'in', 'advance', ',', 'and', 'I', 'had', 'only', 'to', 'set', 'up', 'the', 'easel', 'and', 'get', 'to', 'work', '.', 'He', 'had', 'been', 'dead', 'only', 'twenty-four', 'hours', ',', 'and', 'he', 'died', 'suddenly', ',', 'of', 'heart', 'disease', ',', 'so', 'that', 'there', 'had', 'been', 'no', 'preliminary', 'work', 'of', 'destruction', '--', 'his', 'face', 'was', 'clear', 'and', 'untouched', '.', 'I', 'had', 'met', 'him', 'once', 'or', 'twice', ',', 'years', 'before', ',', 'and', 'thought', 'him', 'insignificant', 'and', 'dingy', '.', 'Now', 'I', 'saw', 'that', 'he', 'was', 'superb', '.', '\"', 'I', 'was', 'glad', 'at', 'first', ',', 'with', 'a', 'merely', 'aesthetic', 'satisfaction', ':', 'glad', 'to', 'have', 'my', 'hand', 'on', 'such', 'a', \"'\", 'subject', '.', \"'\", 'Then', 'his', 'strange', 'life-likeness', 'began', 'to', 'affect', 'me', 'queerly', '--', 'as', 'I', 'blocked', 'the', 'head', 'in', 'I', 'felt', 'as', 'if', 'he', 'were', 'watching', 'me', 'do', 'it', '.', 'The', 'sensation', 'was', 'followed', 'by', 'the', 'thought', ':', 'if', 'he', '_', 'were', '_', 'watching', 'me', ',', 'what', 'would', 'he', 'say', 'to', 'my', 'way', 'of', 'working', '?', 'My', 'strokes', 'began', 'to', 'go', 'a', 'little', 'wild', '--', 'I', 'felt', 'nervous', 'and', 'uncertain', '.', '\"', 'Once', ',', 'when', 'I', 'looked', 'up', ',', 'I', 'seemed', 'to', 'see', 'a', 'smile', 'behind', 'his', 'close', 'grayish', 'beard', '--', 'as', 'if', 'he', 'had', 'the', 'secret', ',', 'and', 'were', 'amusing', 'himself', 'by', 'holding', 'it', 'back', 'from', 'me', '.', 'That', 'exasperated', 'me', 'still', 'more', '.', 'The', 'secret', '?', 'Why', ',', 'I', 'had', 'a', 'secret', 'worth', 'twenty', 'of', 'his', '!', 'I', 'dashed', 'at', 'the', 'canvas', 'furiously', ',', 'and', 'tried', 'some', 'of', 'my', 'bravura', 'tricks', '.', 'But', 'they', 'failed', 'me', ',', 'they', 'crumbled', '.', 'I', 'saw', 'that', 'he', 'wasn', \"'\", 't', 'watching', 'the', 'showy', 'bits', '--', 'I', 'couldn', \"'\", 't', 'distract', 'his', 'attention', ';', 'he', 'just', 'kept', 'his', 'eyes', 'on', 'the', 'hard', 'passages', 'between', '.', 'Those', 'were', 'the', 'ones', 'I', 'had', 'always', 'shirked', ',', 'or', 'covered', 'up', 'with', 'some', 'lying', 'paint', '.', 'And', 'how', 'he', 'saw', 'through', 'my', 'lies', '!', '\"', 'I', 'looked', 'up', 'again', ',', 'and', 'caught', 'sight', 'of', 'that', 'sketch', 'of', 'the', 'donkey', 'hanging', 'on', 'the', 'wall', 'near', 'his', 'bed', '.', 'His', 'wife', 'told', 'me', 'afterward', 'it', 'was', 'the', 'last', 'thing', 'he', 'had', 'done', '--', 'just', 'a', 'note', 'taken', 'with', 'a', 'shaking', 'hand', ',', 'when', 'he', 'was', 'down', 'in', 'Devonshire', 'recovering', 'from', 'a', 'previous', 'heart', 'attack', '.', 'Just', 'a', 'note', '!', 'But', 'it', 'tells', 'his', 'whole', 'history', '.', 'There', 'are', 'years', 'of', 'patient', 'scornful', 'persistence', 'in', 'every', 'line', '.', 'A', 'man', 'who', 'had', 'swum', 'with', 'the', 'current', 'could', 'never', 'have', 'learned', 'that', 'mighty', 'up-stream', 'stroke', '.', '.', '.', '.', '\"', 'I', 'turned', 'back', 'to', 'my', 'work', ',', 'and', 'went', 'on', 'groping', 'and', 'muddling', ';', 'then', 'I', 'looked', 'at', 'the', 'donkey', 'again', '.', 'I', 'saw', 'that', ',', 'when', 'Stroud', 'laid', 'in', 'the', 'first', 'stroke', ',', 'he', 'knew', 'just', 'what', 'the', 'end', 'would', 'be', '.', 'He', 'had', 'possessed', 'his', 'subject', ',', 'absorbed', 'it', ',', 'recreated', 'it', '.', 'When', 'had', 'I', 'done', 'that', 'with', 'any', 'of', 'my', 'things', '?', 'They', 'hadn', \"'\", 't', 'been', 'born', 'of', 'me', '--', 'I', 'had', 'just', 'adopted', 'them', '.', '.', '.', '.', '\"', 'Hang', 'it', ',', 'Rickham', ',', 'with', 'that', 'face', 'watching', 'me', 'I', 'couldn', \"'\", 't', 'do', 'another', 'stroke', '.', 'The', 'plain', 'truth', 'was', ',', 'I', 'didn', \"'\", 't', 'know', 'where', 'to', 'put', 'it', '--', '_', 'I', 'had', 'never', 'known', '_', '.', 'Only', ',', 'with', 'my', 'sitters', 'and', 'my', 'public', ',', 'a', 'showy', 'splash', 'of', 'colour', 'covered', 'up', 'the', 'fact', '--', 'I', 'just', 'threw', 'paint', 'into', 'their', 'faces', '.', '.', '.', '.', 'Well', ',', 'paint', 'was', 'the', 'one', 'medium', 'those', 'dead', 'eyes', 'could', 'see', 'through', '--', 'see', 'straight', 'to', 'the', 'tottering', 'foundations', 'underneath', '.', 'Don', \"'\", 't', 'you', 'know', 'how', ',', 'in', 'talking', 'a', 'foreign', 'language', ',', 'even', 'fluently', ',', 'one', 'says', 'half', 'the', 'time', 'not', 'what', 'one', 'wants', 'to', 'but', 'what', 'one', 'can', '?', 'Well', '--', 'that', 'was', 'the', 'way', 'I', 'painted', ';', 'and', 'as', 'he', 'lay', 'there', 'and', 'watched', 'me', ',', 'the', 'thing', 'they', 'called', 'my', \"'\", 'technique', \"'\", 'collapsed', 'like', 'a', 'house', 'of', 'cards', '.', 'He', 'didn', \"'\", 't', 'sneer', ',', 'you', 'understand', ',', 'poor', 'Stroud', '--', 'he', 'just', 'lay', 'there', 'quietly', 'watching', ',', 'and', 'on', 'his', 'lips', ',', 'through', 'the', 'gray', 'beard', ',', 'I', 'seemed', 'to', 'hear', 'the', 'question', ':', \"'\", 'Are', 'you', 'sure', 'you', 'know', 'where', 'you', \"'\", 're', 'coming', 'out', '?', \"'\", '\"', 'If', 'I', 'could', 'have', 'painted', 'that', 'face', ',', 'with', 'that', 'question', 'on', 'it', ',', 'I', 'should', 'have', 'done', 'a', 'great', 'thing', '.', 'The', 'next', 'greatest', 'thing', 'was', 'to', 'see', 'that', 'I', 'couldn', \"'\", 't', '--', 'and', 'that', 'grace', 'was', 'given', 'me', '.', 'But', ',', 'oh', ',', 'at', 'that', 'minute', ',', 'Rickham', ',', 'was', 'there', 'anything', 'on', 'earth', 'I', 'wouldn', \"'\", 't', 'have', 'given', 'to', 'have', 'Stroud', 'alive', 'before', 'me', ',', 'and', 'to', 'hear', 'him', 'say', ':', \"'\", 'It', \"'\", 's', 'not', 'too', 'late', '--', 'I', \"'\", 'll', 'show', 'you', 'how', \"'\", '?', '\"', 'It', '_', 'was', '_', 'too', 'late', '--', 'it', 'would', 'have', 'been', ',', 'even', 'if', 'he', \"'\", 'd', 'been', 'alive', '.', 'I', 'packed', 'up', 'my', 'traps', ',', 'and', 'went', 'down', 'and', 'told', 'Mrs', '.', 'Stroud', '.', 'Of', 'course', 'I', 'didn', \"'\", 't', 'tell', 'her', '_', 'that', '_', '--', 'it', 'would', 'have', 'been', 'Greek', 'to', 'her', '.', 'I', 'simply', 'said', 'I', 'couldn', \"'\", 't', 'paint', 'him', ',', 'that', 'I', 'was', 'too', 'moved', '.', 'She', 'rather', 'liked', 'the', 'idea', '--', 'she', \"'\", 's', 'so', 'romantic', '!', 'It', 'was', 'that', 'that', 'made', 'her', 'give', 'me', 'the', 'donkey', '.', 'But', 'she', 'was', 'terribly', 'upset', 'at', 'not', 'getting', 'the', 'portrait', '--', 'she', 'did', 'so', 'want', 'him', \"'\", 'done', \"'\", 'by', 'some', 'one', 'showy', '!', 'At', 'first', 'I', 'was', 'afraid', 'she', 'wouldn', \"'\", 't', 'let', 'me', 'off', '--', 'and', 'at', 'my', 'wits', \"'\", 'end', 'I', 'suggested', 'Grindle', '.', 'Yes', ',', 'it', 'was', 'I', 'who', 'started', 'Grindle', ':', 'I', 'told', 'Mrs', '.', 'Stroud', 'he', 'was', 'the', \"'\", 'coming', \"'\", 'man', ',', 'and', 'she', 'told', 'somebody', 'else', ',', 'and', 'so', 'it', 'got', 'to', 'be', 'true', '.', '.', '.', '.', 'And', 'he', 'painted', 'Stroud', 'without', 'wincing', ';', 'and', 'she', 'hung', 'the', 'picture', 'among', 'her', 'husband', \"'\", 's', 'things', '.', '.', '.', '.', '\"', 'He', 'flung', 'himself', 'down', 'in', 'the', 'arm-chair', 'near', 'mine', ',', 'laid', 'back', 'his', 'head', ',', 'and', 'clasping', 'his', 'arms', 'beneath', 'it', ',', 'looked', 'up', 'at', 'the', 'picture', 'above', 'the', 'chimney-piece', '.', '\"', 'I', 'like', 'to', 'fancy', 'that', 'Stroud', 'himself', 'would', 'have', 'given', 'it', 'to', 'me', ',', 'if', 'he', \"'\", 'd', 'been', 'able', 'to', 'say', 'what', 'he', 'thought', 'that', 'day', '.', '\"', 'And', ',', 'in', 'answer', 'to', 'a', 'question', 'I', 'put', 'half-mechanically', '--', '\"', 'Begin', 'again', '?', '\"', 'he', 'flashed', 'out', '.', '\"', 'When', 'the', 'one', 'thing', 'that', 'brings', 'me', 'anywhere', 'near', 'him', 'is', 'that', 'I', 'knew', 'enough', 'to', 'leave', 'off', '?', '\"', 'He', 'stood', 'up', 'and', 'laid', 'his', 'hand', 'on', 'my', 'shoulder', 'with', 'a', 'laugh', '.', '\"', 'Only', 'the', 'irony', 'of', 'it', 'is', 'that', 'I', '_', 'am', '_', 'still', 'painting', '--', 'since', 'Grindle', \"'\", 's', 'doing', 'it', 'for', 'me', '!', 'The', 'Strouds', 'stand', 'alone', ',', 'and', 'happen', 'once', '--', 'but', 'there', \"'\", 's', 'no', 'exterminating', 'our', 'kind', 'of', 'art', '.', '\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total tokens without whitespaces\n",
        "len(preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHgAWdSV0tyW",
        "outputId": "7e60c413-db35-4ea3-ed0e-c9c35e724649"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4690"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first 30 tokens for validation\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJfovbiZ0wMD",
        "outputId": "21631258-b1ee-4507-e0d8-392e651942d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Tokens  --> TokenIDs\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-oQ07lbG59Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating vocab --> unique tokens and thier corresponding integers\n",
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTvD78b-2cSl",
        "outputId": "7259e024-6ef7-42be-bfa3-bd7b18156ce8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab\n",
        "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
        "for i, item in enumerate(vocab.items()):\n",
        "    print(item)\n",
        "    if i > 20:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T52CZp6v6lbn",
        "outputId": "7e26161b-9ce6-4c13-83bb-f79b56aae0ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer class\n",
        "class TokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s, i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "51iOIsXq7H8A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instance of the class\n",
        "tokenizer = TokenizerV1(vocab)\n",
        "text = \"\"\"It's the last he painted, you know,\" Mrs. Gisburn said with pardonable\n",
        "pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhIR4uNdKoyE",
        "outputId": "b4927944-65c1-4530-d0d0-edb00d3df7ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtLINHPpLH-N",
        "outputId": "dbf9ce56-ac8a-49fd-e6c8-0d607d97ec81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Special Context Tokens\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "T0K4RK1HM5Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extend list to special context\n",
        "all_tokens = sorted(list((set(preprocessed))))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R84kNf1vLSAz",
        "outputId": "1af7d1cb-2373-4a28-f3f5-e98af49f2610"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validate\n",
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u2PqqcrLUmy",
        "outputId": "22b0abfe-cbbc-4830-95d0-c89cf2a6a8ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer class\n",
        "class TokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s, i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        preprocessed = [item if item in self.str_to_int\n",
        "         else \"<|unk|>\" for item in preprocessed]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "1Uxh_nIGOkqJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPT3RMkIPbw3",
        "outputId": "28eca9bf-05a3-4653-bee9-e3cd637bab8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TokenizerV2(vocab)\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUXALRT_LUik",
        "outputId": "f3e71339-be30-4d1b-ea53-c1ab122d8418"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Byte-Pair Encoding\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OC5s2Wc6Y3If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "ecIhmQv3LUgg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get GPT-2 bpe encoding\n",
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "udBq8Mk-ZE46"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
        "ids = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAMglsfWZLt4",
        "outputId": "650adde8-9074-46a3-9b06-0a9ea06aecc1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample text\n",
        "sample_text = 'Akwirw ie'\n",
        "ids = tokenizer.encode(sample_text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqMS3WS1eQ-J",
        "outputId": "8be9fd40-11a9-4fd5-d2eb-1b3eb923230a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 37941]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(sample_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3IHYhfwTfBJ8",
        "outputId": "1992d948-7191-4c83-d986-945c0df25af0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Akwirw ie'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Sampling using Sliding Window\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YHJI-Iyrfazg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(len(raw_text))"
      ],
      "metadata": {
        "id": "i0kuhcXYfee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b814d2b9-79a4-452e-f77b-6783a43e9bac"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization using BPE\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(\"Tokens:\", len(enc_text))"
      ],
      "metadata": {
        "id": "1U6klOBLfIjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dce955f-c2c2-4aaa-b9e4-2c1dff0188f9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "enc_sample = enc_text[50:]\n",
        "len(enc_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XErjrI5a6ZfO",
        "outputId": "79f44674-59cc-48f2-fc03-6de05ff8b97a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5095"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input-target pairs\n",
        "context_size = 4\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size + 1]\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:      {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT5-vtIm6y62",
        "outputId": "ecd9d2c7-4e76-475b-85a4-ae5fe66038b7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [290, 4920, 2241, 287]\n",
            "y:      [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "for i in range(1, context_size + 1):\n",
        "    input = enc_sample[:i]\n",
        "    target = enc_sample[i]\n",
        "    print(tokenizer.decode(input), \"-->\", tokenizer.decode([target]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kml_4sF37b7_",
        "outputId": "ea21e655-72ac-4b43-f224-410991de2c80"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and -->  established\n",
            " and established -->  himself\n",
            " and established himself -->  in\n",
            " and established himself in -->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Implementing dataloaders in PyTorch\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "NbMm7EM-9HQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "F8VYKCKw8I-M"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        # sliding window approach\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i: i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_ids[index], self.target_ids[index]"
      ],
      "metadata": {
        "id": "hybyk-W19SKY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader\n",
        "def create_dataloader_v1(txt, batch_size = 4, max_length = 256, stride = 12, shuffle = True):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "    dataloader = DataLoader(dataset, batch_size, shuffle = True, drop_last = True)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "KfLps_Iz-z8Z"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load file\n",
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size = 1, max_length = 4, stride = 1, shuffle = False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHAu3HyAONw4",
        "outputId": "be1d1e69-0d0d-4b02-8aa5-75375cf25e86"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  616, 13674,  5891,   438]]), tensor([[13674,  5891,   438,  1092]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Token Embeddings\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Pc5NojoUP59g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = torch.tensor([2, 3 , 5, 1])\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWVe1ET9OsFc",
        "outputId": "82a054f0-903b-4d9a-b496-58ebc91f207e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 3, 5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "vocab_size = 6\n",
        "output_dim = 3"
      ],
      "metadata": {
        "id": "O7VOMcKIQCNq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0VrswqfQL2-",
        "outputId": "6441f1c2-5f90-4f34-f52f-9250b74ab8dd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample check\n",
        "print(embedding_layer(torch.tensor([5])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7ti7LaZQZyO",
        "outputId": "dc6e94bd-92a2-416b-dee5-6e6faeb6e0f0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.8400, -0.7849, -1.4096]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# token embedding of id\n",
        "print(embedding_layer(torch.tensor(ids)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ51WTdmQs63",
        "outputId": "e2dec6c2-4d30-49e8-c536-ef83c0737ccb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2453163554.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  print(embedding_layer(torch.tensor(ids)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Encoding Word Positions\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5PyTUs3FRbAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# complex embeddings\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "EuHES0DIRIEp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size = 8, max_length = 4, stride = max_length, shuffle = False)\n",
        "data_iter = iter(dataloader)\n",
        "input, target = next(data_iter)\n",
        "print(\"Token IDs:\\n\", input)\n",
        "print(\"\\nInputs shape:\\n\", input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U4VTgVzS3kz",
        "outputId": "95fa2d75-8d5c-427f-d355-e16fd7aab95d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[  262,  4269,    11, 22211],\n",
            "        [  286,   465, 13476,     1],\n",
            "        [ 5493,  2241,   318,   262],\n",
            "        [    1,    40,  3114,   510],\n",
            "        [ 3325,  1299,    11,  3888],\n",
            "        [ 5469,   438, 14363,   938],\n",
            "        [   13,   843,   340,   373],\n",
            "        [  438, 14363, 10568,   852]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(input)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ8EFIcITkMh",
        "outputId": "b3d08d37-652f-4280-ce73-fad97bec26a3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    }
  ]
}